# LLM configuration for iEcoreGen MWE2 workflow
# Replace the placeholder with your actual API key.
# this is deepseeek-r1
#apikey=f0ddfa99-e540-44f2-8a05-024d4ea519da
#timeout=1800

#url=https://ark.cn-beijing.volces.com/api/v3

# Optional settings (uncomment and adjust if needed)
#this is deepseek-chat
# timeout=600
#apikey=sk-9d3b7be7b21f4fd1a981f514c0000522


#gpt-4o-mini,DMXAPI-DeepSeek-R1-70b and gemini-2.5-flash
#url=https://www.dmxapi.com/v1
#apikey=sk-YwH8hctPh8qM67VXMKiMEhJwvl8yYIgLx21KwVZV30GxCAHT

#model=gemini-2.5-flash
#model=deepseek-v3.2-exp

#model=qwen/qwen3-coder
url=https://openrouter.ai/api
timeout=1800
apikey=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
model=meta-llama/llama-4-maverick
#model=deepseek/deepseek-v3.2-exp
#model=openai/gpt-oss-120b
#model=deepseek/deepseek-v3.2-exp